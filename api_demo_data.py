#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäºçœŸå®APIçš„æ¼”ç¤ºæ•°æ®ç”Ÿæˆå™¨

ä½¿ç”¨Buff APIè·å–çœŸå®çš„é¥°å“æ•°æ®ï¼Œå¹¶åˆ†æä»·å·®
"""

import asyncio
import json
import os
import logging
from datetime import datetime
from typing import List

from api_scrapers import collect_sample_api_data, APIDataCollector
from analyzer import PriceDiffAnalyzer
from models import PriceDiffItem

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def generate_api_demo_data(count: int = 200) -> List[PriceDiffItem]:
    """ç”ŸæˆåŸºäºAPIçš„æ¼”ç¤ºæ•°æ®"""
    logger.info(f"å¼€å§‹ç”ŸæˆåŸºäºAPIçš„æ¼”ç¤ºæ•°æ®ï¼Œç›®æ ‡æ•°é‡: {count}")
    
    try:
        # ä½¿ç”¨APIæ”¶é›†çœŸå®æ•°æ®
        logger.info("æ­£åœ¨ä»Buff APIæ”¶é›†æ•°æ®...")
        items = await collect_sample_api_data(count=count)
        
        if not items:
            logger.error("æœªèƒ½è·å–åˆ°ä»»ä½•å•†å“æ•°æ®")
            return []
        
        logger.info(f"æˆåŠŸæ”¶é›† {len(items)} ä¸ªå•†å“æ•°æ®")
        
        # åˆ†æä»·å·®
        analyzer = PriceDiffAnalyzer()
        diff_items = analyzer.analyze_price_diff(items)
        
        # ä¿å­˜æ•°æ®
        analyzer.save_diff_data(diff_items)
        
        logger.info(f"ç”Ÿæˆäº† {len(diff_items)} ä¸ªæœ‰ä»·å·®çš„å•†å“")
        
        return diff_items
        
    except Exception as e:
        logger.error(f"ç”ŸæˆAPIæ¼”ç¤ºæ•°æ®å¤±è´¥: {e}")
        return []

async def generate_large_dataset(max_pages: int = 5) -> List[PriceDiffItem]:
    """ç”Ÿæˆå¤§å‹æ•°æ®é›†"""
    if max_pages is None:
        logger.info("å¼€å§‹ç”Ÿæˆå…¨é‡æ•°æ®é›†ï¼ˆæ‰€æœ‰é¡µé¢ï¼‰...")
    else:
        logger.info(f"å¼€å§‹ç”Ÿæˆå¤§å‹æ•°æ®é›†ï¼Œæœ€å¤§é¡µæ•°: {max_pages}")
    
    try:
        # ä½¿ç”¨APIæ”¶é›†å¤§é‡æ•°æ®
        collector = APIDataCollector()
        items = await collector.collect_all_items(max_pages=max_pages)
        
        if not items:
            logger.error("æœªèƒ½è·å–åˆ°ä»»ä½•å•†å“æ•°æ®")
            return []
        
        logger.info(f"æˆåŠŸæ”¶é›† {len(items)} ä¸ªå•†å“æ•°æ®")
        
        # åˆ†æä»·å·®
        analyzer = PriceDiffAnalyzer()
        diff_items = analyzer.analyze_price_diff(items)
        
        # ä¿å­˜åˆ°ä¸åŒçš„æ–‡ä»¶
        if max_pages is None:
            filename = f"data/api_full_dataset_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        else:
            filename = f"data/api_large_dataset_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        os.makedirs('data', exist_ok=True)
        
        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
        data = []
        for item in diff_items:
            data.append({
                'id': item.skin_item.id,
                'name': item.skin_item.name,
                'buff_price': item.skin_item.buff_price,
                'youpin_price': item.skin_item.youpin_price,
                'price_diff': item.price_diff,
                'profit_margin': item.profit_rate,
                'buff_buy_url': item.buff_buy_url,
                'youpin_url': item.skin_item.youpin_url,
                'image_url': item.skin_item.image_url,
                'category': item.skin_item.category,
                'last_updated': item.skin_item.last_updated.isoformat() if item.skin_item.last_updated else None
            })
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"å¤§å‹æ•°æ®é›†å·²ä¿å­˜åˆ° {filename}")
        logger.info(f"ç”Ÿæˆäº† {len(diff_items)} ä¸ªæœ‰ä»·å·®çš„å•†å“")
        
        return diff_items
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆå¤§å‹æ•°æ®é›†å¤±è´¥: {e}")
        return []

def print_statistics(diff_items: List[PriceDiffItem]):
    """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
    if not diff_items:
        print("âŒ æ²¡æœ‰æ•°æ®å¯ä»¥åˆ†æ")
        return
    
    analyzer = PriceDiffAnalyzer()
    stats = analyzer.get_statistics(diff_items)
    
    print("\nğŸ“Š APIæ•°æ®ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   æ€»å•†å“æ•°é‡: {stats['total_count']}")
    print(f"   å¹³å‡ä»·å·®: Â¥{stats['avg_price_diff']:.2f}")
    print(f"   æœ€å¤§ä»·å·®: Â¥{stats['max_price_diff']:.2f}")
    print(f"   æœ€å°ä»·å·®: Â¥{stats['min_price_diff']:.2f}")
    print(f"   å¹³å‡åˆ©æ¶¦ç‡: {stats['avg_profit_rate']:.1f}%")
    print(f"   æœ€å¤§åˆ©æ¶¦ç‡: {stats['max_profit_rate']:.1f}%")
    
    # æŒ‰ç±»åˆ«ç»Ÿè®¡
    categories = {}
    for item in diff_items:
        category = item.skin_item.category or "æœªçŸ¥"
        if category not in categories:
            categories[category] = []
        categories[category].append(item.price_diff)
    
    print(f"\nğŸ·ï¸ ç±»åˆ«ç»Ÿè®¡:")
    for category, price_diffs in sorted(categories.items(), key=lambda x: len(x[1]), reverse=True)[:5]:
        avg_diff = sum(price_diffs) / len(price_diffs)
        print(f"   {category}: {len(price_diffs)} ä¸ªï¼Œå¹³å‡ä»·å·® Â¥{avg_diff:.2f}")
    
    # é«˜ä»·å·®å•†å“
    high_diff_items = sorted(diff_items, key=lambda x: x.price_diff, reverse=True)[:5]
    print(f"\nğŸ’° ä»·å·®æœ€é«˜çš„5ä¸ªå•†å“:")
    for i, item in enumerate(high_diff_items, 1):
        print(f"   {i}. {item.skin_item.name}")
        print(f"      ä»·å·®: Â¥{item.price_diff:.2f} ({item.profit_rate:.1f}%)")
        print(f"      Buff: Â¥{item.skin_item.buff_price} â†’ æ‚ æ‚ æœ‰å“: Â¥{item.skin_item.youpin_price}")

async def save_api_demo_data():
    """ä¿å­˜APIæ¼”ç¤ºæ•°æ®çš„ä¾¿æ·å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ç”ŸæˆåŸºäºçœŸå®APIçš„æ¼”ç¤ºæ•°æ®...")
    
    # ç”Ÿæˆæ¼”ç¤ºæ•°æ®
    diff_items = await generate_api_demo_data(count=100)
    
    if diff_items:
        print_statistics(diff_items)
        print(f"\nâœ… APIæ¼”ç¤ºæ•°æ®ç”Ÿæˆå®Œæˆï¼å…± {len(diff_items)} ä¸ªæœ‰ä»·å·®å•†å“")
        print("ğŸ’¡ æ•°æ®å·²ä¿å­˜åˆ° data/price_diff_analysis.json")
    else:
        print("âŒ APIæ¼”ç¤ºæ•°æ®ç”Ÿæˆå¤±è´¥")

async def save_large_api_dataset():
    """ä¿å­˜å¤§å‹APIæ•°æ®é›†çš„ä¾¿æ·å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ç”Ÿæˆå¤§å‹APIæ•°æ®é›†...")
    
    # ç”Ÿæˆå¤§å‹æ•°æ®é›†
    diff_items = await generate_large_dataset(max_pages=3)
    
    if diff_items:
        print_statistics(diff_items)
        print(f"\nâœ… å¤§å‹APIæ•°æ®é›†ç”Ÿæˆå®Œæˆï¼å…± {len(diff_items)} ä¸ªæœ‰ä»·å·®å•†å“")
    else:
        print("âŒ å¤§å‹APIæ•°æ®é›†ç”Ÿæˆå¤±è´¥")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "--large":
        # ç”Ÿæˆå¤§å‹æ•°æ®é›†
        asyncio.run(save_large_api_dataset())
    else:
        # ç”Ÿæˆæ¼”ç¤ºæ•°æ®
        asyncio.run(save_api_demo_data()) 