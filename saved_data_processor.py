#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»å·²ä¿å­˜æ•°æ®é‡æ–°å¤„ç†ç­›é€‰ - ä¿®å¤ç‰ˆæœ¬

å½“ç­›é€‰æ¡ä»¶æ›´æ–°æ—¶ï¼Œä»å·²ä¿å­˜çš„å…¨é‡æ•°æ®ä¸­é‡æ–°ç­›é€‰ï¼Œé¿å…é‡å¤APIè°ƒç”¨
"""

import json
import os
import logging
import time
from datetime import datetime
from typing import List, Dict, Optional, Tuple, Set
from models import PriceDiffItem, SkinItem
from config import Config

# å¯¼å…¥æ”¹è¿›çš„åŒ¹é…å™¨ï¼ˆé¿å…å¾ªç¯å¯¼å…¥ï¼Œè¿™é‡Œé‡æ–°å®šä¹‰ï¼‰
import re
from difflib import SequenceMatcher

class ImprovedMatcher:
    """æ”¹è¿›çš„å•†å“åŒ¹é…å™¨ï¼ˆæœ¬åœ°ç‰ˆæœ¬ï¼‰"""
    
    def __init__(self):
        self.exact_matches = 0
        self.normalized_matches = 0
        self.weapon_matches = 0
        self.fuzzy_matches = 0
        self.no_matches = 0
    
    def normalize_hash_name(self, hash_name: str) -> str:
        """è§„èŒƒåŒ–Hashåç§°"""
        if not hash_name:
            return ""
        
        # 1. ç§»é™¤å¤šä½™ç©ºæ ¼
        normalized = re.sub(r'\s+', ' ', hash_name.strip())
        
        # 2. ç»Ÿä¸€ç‰¹æ®Šå­—ç¬¦
        normalized = normalized.replace('ï¼ˆ', '(').replace('ï¼‰', ')')
        normalized = normalized.replace('ï½œ', '|')
        
        return normalized
    
    # ğŸš« å·²ç¦ç”¨æ­¤æ–¹æ³• - ç§»é™¤ç£¨æŸç­‰çº§å’ŒStatTrakæ ‡è®°ä¼šå¯¼è‡´ä»·æ ¼åŒ¹é…é”™è¯¯
    # def extract_weapon_name(self, hash_name: str) -> str:
    #     """æå–æ­¦å™¨åç§°ï¼ˆå»é™¤ç£¨æŸç­‰çº§ï¼‰"""
    #     if not hash_name:
    #         return ""
    #     
    #     # ç§»é™¤ç£¨æŸç­‰çº§
    #     weapon_name = re.sub(r'\s*\([^)]*\)\s*$', '', hash_name)
    #     
    #     # ç§»é™¤ StatTrakâ„¢ æ ‡è®°è¿›è¡Œæ›´å¹¿æ³›çš„åŒ¹é…
    #     weapon_name_no_stattrak = re.sub(r'StatTrakâ„¢?\s*', '', weapon_name)
    #     
    #     return weapon_name_no_stattrak.strip()
    
    def calculate_similarity(self, str1: str, str2: str) -> float:
        """è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦"""
        if not str1 or not str2:
            return 0.0
        
        return SequenceMatcher(None, str1.lower(), str2.lower()).ratio()
    
    def find_best_match(self, buff_hash: str, youpin_hashes: Set[str], 
                       youpin_price_map: Dict[str, float]) -> Optional[Tuple[float, str, str]]:
        """ä¸ºBuffå•†å“æ‰¾åˆ°æœ€ä½³åŒ¹é…çš„æ‚ æ‚ æœ‰å“å•†å“"""
        if not buff_hash or not youpin_hashes:
            return None
        
        # 1. ç²¾ç¡®åŒ¹é…
        if buff_hash in youpin_hashes and buff_hash in youpin_price_map:
            self.exact_matches += 1
            return (youpin_price_map[buff_hash], "ç²¾ç¡®åŒ¹é…", buff_hash)
        
        # 2. è§„èŒƒåŒ–åç²¾ç¡®åŒ¹é…
        normalized_buff = self.normalize_hash_name(buff_hash)
        for youpin_hash in youpin_hashes:
            normalized_youpin = self.normalize_hash_name(youpin_hash)
            if normalized_buff == normalized_youpin and youpin_hash in youpin_price_map:
                self.normalized_matches += 1
                return (youpin_price_map[youpin_hash], "è§„èŒƒåŒ–åŒ¹é…", youpin_hash)
        
        # ğŸš« ç¬¬3ç§åŒ¹é…å·²ç¦ç”¨ - ç§»é™¤ç£¨æŸç­‰çº§å’ŒStatTrakæ ‡è®°ä¼šå¯¼è‡´ä»·æ ¼åŒ¹é…é”™è¯¯
        # ç£¨æŸç­‰çº§ï¼ˆField-Tested, Minimal Wearç­‰ï¼‰å’ŒStatTrakâ„¢æ ‡è®°æ˜¯å½±å“ä»·æ ¼çš„æ ¸å¿ƒç‰¹å¾
        # ç§»é™¤è¿™äº›ç‰¹å¾ä¼šå¯¼è‡´åŒ¹é…åˆ°é”™è¯¯çš„å•†å“ï¼Œé€ æˆä¸¥é‡çš„ä»·æ ¼åˆ¤æ–­é”™è¯¯
        
        # ğŸ”¥ ç¦ç”¨æ‰€æœ‰å¯èƒ½é€ æˆé”™è¯¯åŒ¹é…çš„ç®—æ³• - åªä¿ç•™ç²¾ç¡®åŒ¹é…
        # å¯¹äº24K+å•†å“ï¼Œæ¨¡ç³ŠåŒ¹é…ä¼šå¯¼è‡´5äº¿æ¬¡è®¡ç®—ï¼Œæ€§èƒ½æå·®
        # åŒæ—¶ç§»é™¤ç£¨æŸç­‰çº§ç­‰é‡è¦ç‰¹å¾ä¼šé€ æˆä»·æ ¼åŒ¹é…é”™è¯¯
        
        # # 3. æ­¦å™¨åç§°åŒ¹é…ï¼ˆå»é™¤ç£¨æŸç­‰çº§ï¼‰  -- å·²ç¦ç”¨ï¼Œä¼šé€ æˆä»·æ ¼é”™è¯¯
        # # 4. é«˜ç›¸ä¼¼åº¦æ¨¡ç³ŠåŒ¹é…ï¼ˆ90%ä»¥ä¸Šç›¸ä¼¼åº¦ï¼‰  -- å·²ç¦ç”¨ï¼Œæ€§èƒ½é—®é¢˜  
        # # 5. æ­¦å™¨åç§°æ¨¡ç³ŠåŒ¹é…ï¼ˆ85%ä»¥ä¸Šç›¸ä¼¼åº¦ï¼‰  -- å·²ç¦ç”¨ï¼Œæ€§èƒ½é—®é¢˜
        
        # æ²¡æœ‰æ‰¾åˆ°åŒ¹é…
        self.no_matches += 1
        return None
    
    def find_best_match_fast(self, buff_hash: str, youpin_price_map: Dict[str, float], 
                            normalized_youpin_map: Dict[str, List[str]]) -> Optional[Tuple[float, str, str]]:
        """ğŸš€ é«˜æ€§èƒ½åŒ¹é…æ–¹æ³•ï¼šä½¿ç”¨é¢„å»ºç´¢å¼•è¿›è¡Œå¿«é€ŸåŒ¹é…"""
        if not buff_hash:
            return None
        
        # 1. ç²¾ç¡®åŒ¹é… - O(1)å¤æ‚åº¦
        if buff_hash in youpin_price_map:
            self.exact_matches += 1
            return (youpin_price_map[buff_hash], "ç²¾ç¡®åŒ¹é…", buff_hash)
        
        # 2. è§„èŒƒåŒ–åŒ¹é… - O(1)å¤æ‚åº¦æŸ¥æ‰¾ï¼Œä¸éœ€è¦éå†
        normalized_buff = self.normalize_hash_name(buff_hash)
        candidate_hashes = normalized_youpin_map.get(normalized_buff, [])
        
        for youpin_hash in candidate_hashes:
            if youpin_hash in youpin_price_map:
                self.normalized_matches += 1
                return (youpin_price_map[youpin_hash], "è§„èŒƒåŒ–åŒ¹é…", youpin_hash)
        
        # æ²¡æœ‰æ‰¾åˆ°åŒ¹é…
        self.no_matches += 1
        return None
    
    def get_statistics(self) -> Dict[str, int]:
        """è·å–åŒ¹é…ç»Ÿè®¡ä¿¡æ¯"""
        total = self.exact_matches + self.normalized_matches + self.weapon_matches + self.fuzzy_matches + self.no_matches
        
        return {
            'total_processed': total,
            'exact_matches': self.exact_matches,
            'normalized_matches': self.normalized_matches,
            'weapon_matches': self.weapon_matches,
            'fuzzy_matches': self.fuzzy_matches,
            'no_matches': self.no_matches,
            'total_matches': total - self.no_matches,
            'match_rate': ((total - self.no_matches) / total * 100) if total > 0 else 0
        }

logger = logging.getLogger(__name__)

class SavedDataProcessor:
    """ä»å·²ä¿å­˜æ•°æ®é‡æ–°å¤„ç†ç­›é€‰"""
    
    def __init__(self, data_dir: str = "data"):
        self.data_dir = data_dir
    
    def get_latest_full_data_files(self) -> Dict[str, Optional[str]]:
        """è·å–å…¨é‡æ•°æ®æ–‡ä»¶ï¼ˆæ”¯æŒæ–°æ—§ä¸¤ç§å‘½åæ–¹å¼ï¼‰"""
        try:
            if not os.path.exists(self.data_dir):
                logger.warning(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.data_dir}")
                return {'buff_file': None, 'youpin_file': None}
            
            # ä¼˜å…ˆæŸ¥æ‰¾æ–°çš„å›ºå®šæ–‡ä»¶å
            buff_file = "buff_full.json"
            youpin_file = "youpin_full.json"
            
            buff_exists = os.path.exists(os.path.join(self.data_dir, buff_file))
            youpin_exists = os.path.exists(os.path.join(self.data_dir, youpin_file))
            
            # å¦‚æœæ–°æ–‡ä»¶å­˜åœ¨ï¼Œç›´æ¥ä½¿ç”¨
            if buff_exists and youpin_exists:
                logger.info(f"ğŸ“‚ æ‰¾åˆ°æ–°ç‰ˆå…¨é‡æ•°æ®æ–‡ä»¶: {buff_file}, {youpin_file}")
                return {'buff_file': buff_file, 'youpin_file': youpin_file}
            
            # å¦‚æœæ–°æ–‡ä»¶ä¸å­˜åœ¨ï¼ŒæŸ¥æ‰¾æ—§çš„æ—¶é—´æˆ³æ–‡ä»¶ä½œä¸ºå…¼å®¹
            buff_files = []
            youpin_files = []
            
            for filename in os.listdir(self.data_dir):
                if filename.startswith('buff_full_') and filename.endswith('.json'):
                    buff_files.append(filename)
                elif filename.startswith('youpin_full_') and filename.endswith('.json'):
                    youpin_files.append(filename)
            
            # æŒ‰æ—¶é—´æˆ³æ’åºï¼Œè·å–æœ€æ–°çš„
            buff_files.sort(reverse=True)
            youpin_files.sort(reverse=True)
            
            result = {
                'buff_file': buff_files[0] if buff_files else None,
                'youpin_file': youpin_files[0] if youpin_files else None
            }
            
            if result['buff_file'] and result['youpin_file']:
                logger.info(f"ğŸ“‚ æ‰¾åˆ°æ—§ç‰ˆæ•°æ®æ–‡ä»¶: Buff={result['buff_file']}, æ‚ æ‚ æœ‰å“={result['youpin_file']}")
                logger.info(f"ğŸ’¡ å»ºè®®è¿è¡Œå…¨é‡æ›´æ–°ä»¥ç”Ÿæˆæ–°ç‰ˆå›ºå®šæ–‡ä»¶å")
            else:
                logger.warning(f"âš ï¸ ç¼ºå°‘å…¨é‡æ•°æ®æ–‡ä»¶: Buff={result['buff_file']}, æ‚ æ‚ æœ‰å“={result['youpin_file']}")
            
            return result
            
        except Exception as e:
            logger.error(f"è·å–å…¨é‡æ•°æ®æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {e}")
            return {'buff_file': None, 'youpin_file': None}
    
    def load_saved_data(self, filepath: str) -> Optional[Dict]:
        """åŠ è½½å·²ä¿å­˜çš„æ•°æ®æ–‡ä»¶"""
        try:
            full_path = os.path.join(self.data_dir, filepath)
            if not os.path.exists(full_path):
                logger.error(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {full_path}")
                return None
                
            with open(full_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            items_count = len(data.get('items', []))
            logger.info(f"âœ… åŠ è½½æ•°æ®æ–‡ä»¶: {filepath} ({items_count}ä¸ªå•†å“)")
            return data
            
        except Exception as e:
            logger.error(f"åŠ è½½æ•°æ®æ–‡ä»¶å¤±è´¥ {filepath}: {e}")
            return None
    
    def has_valid_full_data(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„å…¨é‡æ•°æ®æ–‡ä»¶"""
        files = self.get_latest_full_data_files()
        return files['buff_file'] is not None and files['youpin_file'] is not None
    
    def reprocess_with_current_filters(self) -> Tuple[List[PriceDiffItem], Dict]:
        """ä½¿ç”¨å½“å‰ç­›é€‰æ¡ä»¶é‡æ–°å¤„ç†å·²ä¿å­˜çš„æ•°æ®"""
        logger.info("ğŸ”„ å¼€å§‹ä»å·²ä¿å­˜æ•°æ®é‡æ–°ç­›é€‰...")
        
        # 1. è·å–æœ€æ–°çš„æ•°æ®æ–‡ä»¶
        files = self.get_latest_full_data_files()
        buff_file = files['buff_file']
        youpin_file = files['youpin_file']
        
        if not buff_file or not youpin_file:
            logger.warning("âŒ ç¼ºå°‘å…¨é‡æ•°æ®æ–‡ä»¶ï¼Œæ— æ³•é‡æ–°ç­›é€‰")
            return [], {'error': 'ç¼ºå°‘å…¨é‡æ•°æ®æ–‡ä»¶ï¼Œè¯·å…ˆæ‰§è¡Œå…¨é‡æ›´æ–°'}
        
        # 2. åŠ è½½æ•°æ®
        buff_data = self.load_saved_data(buff_file)
        youpin_data = self.load_saved_data(youpin_file)
        
        if not buff_data or not youpin_data:
            logger.error("âŒ æ•°æ®æ–‡ä»¶åŠ è½½å¤±è´¥")
            return [], {'error': 'æ•°æ®æ–‡ä»¶åŠ è½½å¤±è´¥'}
        
        buff_items = buff_data.get('items', [])
        youpin_items = youpin_data.get('items', [])
        
        logger.info(f"ğŸ“Š åŠ è½½æ•°æ®: Buff {len(buff_items)}ä¸ª, æ‚ æ‚ æœ‰å“ {len(youpin_items)}ä¸ª")
        
        # 3. é‡æ–°æ‰§è¡Œç­›é€‰åˆ†æ
        diff_items, stats = self._analyze_with_current_filters(buff_items, youpin_items)
        
        # 4. æ·»åŠ æ–‡ä»¶ä¿¡æ¯åˆ°ç»Ÿè®¡
        stats.update({
            'buff_file': buff_file,
            'youpin_file': youpin_file,
            'buff_file_time': buff_data.get('metadata', {}).get('generated_at'),
            'youpin_file_time': youpin_data.get('metadata', {}).get('generated_at'),
            'reprocessed_at': datetime.now().isoformat()
        })
        
        logger.info(f"âœ… é‡æ–°ç­›é€‰å®Œæˆ: ç¬¦åˆæ¡ä»¶çš„å•†å“ {len(diff_items)}ä¸ª")
        
        return diff_items, stats
    
    def _analyze_with_current_filters(self, buff_items: List[Dict], youpin_items: List[Dict]) -> Tuple[List[PriceDiffItem], Dict]:
        """ä½¿ç”¨å½“å‰ç­›é€‰æ¡ä»¶åˆ†ææ•°æ®"""
        diff_items = []
        stats = {
            'total_buff_items': len(buff_items),
            'total_youpin_items': len(youpin_items),
            'processed_count': 0,
            'found_count': 0,
            'hash_match_count': 0,
            'name_match_count': 0,
            'price_filtered_count': 0,
            'sell_num_filtered_count': 0,
            'after_price_filter_count': 0,  # ğŸ”¥ æ–°å¢ï¼šä»·æ ¼ç­›é€‰åå‰©ä½™å•†å“æ•°
            'after_sell_num_filter_count': 0,  # ğŸ”¥ æ–°å¢ï¼šåœ¨å”®æ•°é‡ç­›é€‰åå‰©ä½™å•†å“æ•°
            'final_count': 0,
            'creation_errors': 0
        }
        
        # å»ºç«‹æ‚ æ‚ æœ‰å“ä»·æ ¼æ˜ å°„
        youpin_hash_map = {}
        youpin_name_map = {}
        
        for item in youpin_items:
            hash_name = item.get('commodityHashName', '')
            commodity_name = item.get('commodityName', '')
            price = item.get('price', 0)
            
            if hash_name and price:
                try:
                    youpin_hash_map[hash_name] = float(price)
                except (ValueError, TypeError):
                    continue
            
            if commodity_name and price:
                try:
                    youpin_name_map[commodity_name] = float(price)
                except (ValueError, TypeError):
                    continue
        
        logger.info(f"ğŸ“ˆ å»ºç«‹æ˜ å°„è¡¨: Hashæ˜ å°„{len(youpin_hash_map)}ä¸ª, åç§°æ˜ å°„{len(youpin_name_map)}ä¸ª")
        
        # ğŸ”¥ ç¬¬ä¸€æ­¥ï¼šä»·æ ¼ç­›é€‰
        logger.info(f"ğŸ”¥ å¼€å§‹ç¬¬ä¸€æ­¥ç­›é€‰ï¼šä»·æ ¼åŒºé—´ {Config.BUFF_PRICE_MIN}-{Config.BUFF_PRICE_MAX}å…ƒ")
        price_filtered_items = []
        
        for item_data in buff_items:
            stats['processed_count'] += 1
            
            # è§£æåŸºæœ¬ä¿¡æ¯
            buff_price_str = item_data.get('sell_min_price', '0')
            
            # å¤„ç†ä»·æ ¼
            try:
                buff_price = float(buff_price_str) if buff_price_str else 0.0
            except (ValueError, TypeError):
                buff_price = 0.0
            
            if not buff_price or buff_price <= 0:
                continue
            
            # ğŸ”¥ ç¬¬ä¸€æ­¥ç­›é€‰ï¼šä»·æ ¼åŒºé—´
            if not Config.is_buff_price_in_range(buff_price):
                stats['price_filtered_count'] += 1
                continue
            
            # é€šè¿‡ä»·æ ¼ç­›é€‰çš„å•†å“
            price_filtered_items.append(item_data)
        
        stats['after_price_filter_count'] = len(price_filtered_items)
        logger.info(f"   ç¬¬ä¸€æ­¥å®Œæˆï¼š{stats['price_filtered_count']}ä¸ªå•†å“è¢«ä»·æ ¼ç­›é€‰è¿‡æ»¤ï¼Œå‰©ä½™{stats['after_price_filter_count']}ä¸ª")
        
        # ğŸ”¥ ç¬¬äºŒæ­¥ï¼šåœ¨å”®æ•°é‡ç­›é€‰
        logger.info(f"ğŸ”¥ å¼€å§‹ç¬¬äºŒæ­¥ç­›é€‰ï¼šåœ¨å”®æ•°é‡ â‰¥{Config.BUFF_SELL_NUM_MIN}ä¸ª")
        final_filtered_items = []
        
        for item_data in price_filtered_items:
            sell_num = item_data.get('sell_num', 0)
            
            # ğŸ”¥ ç¬¬äºŒæ­¥ç­›é€‰ï¼šåœ¨å”®æ•°é‡
            if not Config.is_buff_sell_num_valid(sell_num):
                stats['sell_num_filtered_count'] += 1
                continue
            
            # é€šè¿‡æ‰€æœ‰ç­›é€‰çš„å•†å“
            final_filtered_items.append(item_data)
        
        stats['after_sell_num_filter_count'] = len(final_filtered_items)
        logger.info(f"   ç¬¬äºŒæ­¥å®Œæˆï¼š{stats['sell_num_filtered_count']}ä¸ªå•†å“è¢«åœ¨å”®æ•°é‡ç­›é€‰è¿‡æ»¤ï¼Œå‰©ä½™{stats['after_sell_num_filter_count']}ä¸ª")
        
        # ğŸ”¥ ä½¿ç”¨æ”¹è¿›çš„åŒ¹é…ç®—æ³•å¹¶é¢„å»ºç´¢å¼•
        improved_matcher = ImprovedMatcher()
        youpin_hashes = set(youpin_hash_map.keys())
        
        # ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šé¢„å»ºè§„èŒƒåŒ–æ˜ å°„è¡¨ï¼Œé¿å…é‡å¤è®¡ç®—
        logger.info(f"ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šé¢„å»ºè§„èŒƒåŒ–æ˜ å°„è¡¨...")
        normalized_youpin_map = {}
        for youpin_hash in youpin_hashes:
            normalized = improved_matcher.normalize_hash_name(youpin_hash)
            if normalized not in normalized_youpin_map:
                normalized_youpin_map[normalized] = []
            normalized_youpin_map[normalized].append(youpin_hash)
        
        logger.info(f"âœ… æ˜ å°„è¡¨å»ºç«‹å®Œæˆï¼š{len(normalized_youpin_map)}ä¸ªè§„èŒƒåŒ–é”®")
        
        # å¤„ç†é€šè¿‡ç­›é€‰çš„å•†å“
        logger.info(f"ğŸ”¥ å¼€å§‹åŒ¹é…é˜¶æ®µï¼šå¤„ç†{len(final_filtered_items)}ä¸ªé€šè¿‡ç­›é€‰çš„å•†å“")
        match_start_time = time.time()
        processed_in_match = 0
        
        for item_data in final_filtered_items:
            processed_in_match += 1
            
            # ğŸš€ æ¯å¤„ç†1000ä¸ªå•†å“æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
            if processed_in_match % 1000 == 0:
                elapsed = time.time() - match_start_time
                rate = processed_in_match / elapsed if elapsed > 0 else 0
                logger.info(f"   åŒ¹é…è¿›åº¦: {processed_in_match}/{len(final_filtered_items)} ({rate:.0f}ä¸ª/ç§’)")
            # è§£æåŸºæœ¬ä¿¡æ¯
            buff_id = str(item_data.get('id', ''))
            buff_name = item_data.get('name', '')
            buff_price_str = item_data.get('sell_min_price', '0')
            hash_name = item_data.get('market_hash_name', '')
            sell_num = item_data.get('sell_num', 0)
            
            # å¤„ç†ä»·æ ¼ï¼ˆå·²ç»é€šè¿‡ç­›é€‰ï¼Œè¿™é‡Œåªæ˜¯ä¸ºäº†è®¡ç®—ï¼‰
            try:
                buff_price = float(buff_price_str) if buff_price_str else 0.0
            except (ValueError, TypeError):
                buff_price = 0.0
            
            # ğŸš€ ä½¿ç”¨é«˜æ€§èƒ½åŒ¹é…ç®—æ³•ï¼ˆé¢„å»ºç´¢å¼•ï¼‰
            match_result = improved_matcher.find_best_match_fast(
                hash_name, 
                youpin_hash_map,
                normalized_youpin_map
            )
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…ï¼Œè·³è¿‡
            if not match_result:
                continue
            
            youpin_price, matched_by, matched_name = match_result
            stats['found_count'] += 1
            
            # è®¡ç®—ä»·å·®
            price_diff = youpin_price - buff_price
            profit_rate = (price_diff / buff_price) * 100 if buff_price > 0 else 0
            
            # ğŸ”¥ åº”ç”¨ä»·å·®åŒºé—´ç­›é€‰
            if Config.is_price_diff_in_range(price_diff):
                try:
                    # ğŸ”¥ ä¿®å¤ï¼šæ­£ç¡®åˆ›å»ºSkinItemå’ŒPriceDiffItem
                    skin_item = SkinItem(
                        id=buff_id,
                        name=buff_name,
                        buff_price=buff_price,
                        youpin_price=youpin_price,
                        buff_url=f"https://buff.163.com/goods/{buff_id}",
                        youpin_url=f"https://www.youpin898.com/search?keyword={buff_name}",
                        image_url=item_data.get('goods_info', {}).get('icon_url', ''),
                        hash_name=hash_name,
                        sell_num=sell_num,
                        category="é‡æ–°ç­›é€‰",
                        last_updated=datetime.now()
                    )
                    
                    diff_item = PriceDiffItem(
                        skin_item=skin_item,
                        price_diff=price_diff,
                        profit_rate=profit_rate,
                        buff_buy_url=f"https://buff.163.com/goods/{buff_id}"
                    )
                    
                    diff_items.append(diff_item)
                    stats['final_count'] += 1
                    
                except Exception as e:
                    logger.error(f"åˆ›å»ºPriceDiffItemå¤±è´¥: {e}")
                    logger.error(f"å•†å“æ•°æ®: id={buff_id}, name={buff_name}, buff_price={buff_price}, youpin_price={youpin_price}")
                    stats['creation_errors'] += 1
                    continue
        
        # æŒ‰åˆ©æ¶¦ç‡æ’åº
        diff_items.sort(key=lambda x: x.profit_rate, reverse=True)
        
        # é™åˆ¶è¾“å‡ºæ•°é‡
        original_count = len(diff_items)
        if len(diff_items) > Config.MAX_OUTPUT_ITEMS:
            diff_items = diff_items[:Config.MAX_OUTPUT_ITEMS]
            stats['limited_output'] = True
            stats['original_final_count'] = original_count
        else:
            stats['limited_output'] = False
        
        # æ·»åŠ ç­›é€‰æ¡ä»¶ä¿¡æ¯
        stats['filters_applied'] = {
            'price_diff_range': f"{Config.PRICE_DIFF_MIN}-{Config.PRICE_DIFF_MAX}å…ƒ",
            'buff_price_range': f"{Config.BUFF_PRICE_MIN}-{Config.BUFF_PRICE_MAX}å…ƒ",
            'buff_sell_num_min': Config.get_buff_sell_num_min(),
            'max_output_items': Config.MAX_OUTPUT_ITEMS
        }
        
        # ğŸš€ åŒ¹é…é˜¶æ®µæ€§èƒ½ç»Ÿè®¡
        match_end_time = time.time()
        match_duration = match_end_time - match_start_time
        match_rate = len(final_filtered_items) / match_duration if match_duration > 0 else 0
        
        logger.info(f"âœ… åŒ¹é…é˜¶æ®µå®Œæˆï¼šè€—æ—¶ {match_duration:.2f}ç§’ï¼Œå¤„ç†é€Ÿåº¦ {match_rate:.0f}ä¸ª/ç§’")
        
        # ğŸ”¥ æ·»åŠ æ”¹è¿›åŒ¹é…ç®—æ³•çš„ç»Ÿè®¡ä¿¡æ¯
        matcher_stats = improved_matcher.get_statistics()
        stats.update({
            'match_duration_seconds': match_duration,
            'match_rate_per_second': match_rate,
            'matcher_exact_matches': matcher_stats['exact_matches'],
            'matcher_normalized_matches': matcher_stats['normalized_matches'],
            'matcher_weapon_matches': matcher_stats['weapon_matches'],
            'matcher_fuzzy_matches': matcher_stats['fuzzy_matches'],
            'matcher_no_matches': matcher_stats['no_matches'],
            'matcher_total_matches': matcher_stats['total_matches'],
            'matcher_match_rate': matcher_stats['match_rate']
        })
        
        logger.info(f"ğŸ“Š ç­›é€‰ç»Ÿè®¡:")
        logger.info(f"   å¤„ç†å•†å“: {stats['processed_count']}ä¸ª")
        logger.info(f"   ğŸ”¥ ç¬¬ä¸€æ­¥-ä»·æ ¼ç­›é€‰: è¿‡æ»¤{stats['price_filtered_count']}ä¸ª â†’ å‰©ä½™{stats['after_price_filter_count']}ä¸ª")
        logger.info(f"   ğŸ”¥ ç¬¬äºŒæ­¥-åœ¨å”®æ•°é‡ç­›é€‰: è¿‡æ»¤{stats['sell_num_filtered_count']}ä¸ª â†’ å‰©ä½™{stats['after_sell_num_filter_count']}ä¸ª")
        logger.info(f"   æ‰¾åˆ°åŒ¹é…: {stats['found_count']}ä¸ª (åŒ¹é…ç‡:{matcher_stats['match_rate']:.1f}%)")
        logger.info(f"   ğŸ¯ åŒ¹é…ç±»å‹åˆ†å¸ƒ:")
        logger.info(f"      ç²¾ç¡®åŒ¹é…: {matcher_stats['exact_matches']}ä¸ª")
        logger.info(f"      è§„èŒƒåŒ–åŒ¹é…: {matcher_stats['normalized_matches']}ä¸ª")
        logger.info(f"      æ­¦å™¨åç§°åŒ¹é…: {matcher_stats['weapon_matches']}ä¸ª")
        logger.info(f"      æ¨¡ç³ŠåŒ¹é…: {matcher_stats['fuzzy_matches']}ä¸ª")
        logger.info(f"      æœªåŒ¹é…: {matcher_stats['no_matches']}ä¸ª")
        logger.info(f"   ç¬¦åˆä»·å·®æ¡ä»¶: {stats['final_count']}ä¸ª")
        if stats['creation_errors'] > 0:
            logger.warning(f"   åˆ›å»ºé”™è¯¯: {stats['creation_errors']}ä¸ª")
        
        return diff_items, stats

# å…¨å±€å®ä¾‹
_saved_data_processor = None

def get_saved_data_processor() -> SavedDataProcessor:
    """è·å–å…¨å±€çš„ä¿å­˜æ•°æ®å¤„ç†å™¨å®ä¾‹"""
    global _saved_data_processor
    if _saved_data_processor is None:
        _saved_data_processor = SavedDataProcessor()
    return _saved_data_processor 