#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è°ƒè¯•Buffçˆ¬è™«é—®é¢˜
"""

import requests
from bs4 import BeautifulSoup
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_buff_access():
    """æµ‹è¯•Buffç½‘ç«™è®¿é—®"""
    base_url = "https://buff.163.com"
    
    # è®¾ç½®è¯·æ±‚å¤´
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3',
        'Accept-Encoding': 'gzip, deflate',
        'Connection': 'keep-alive'
    }
    
    try:
        print("ğŸ” æµ‹è¯•Buffç½‘ç«™è®¿é—®...")
        url = f"{base_url}/market/csgo"
        
        session = requests.Session()
        session.headers.update(headers)
        
        response = session.get(url, timeout=10)
        
        print(f"çŠ¶æ€ç : {response.status_code}")
        print(f"å“åº”é•¿åº¦: {len(response.content)} bytes")
        print(f"Content-Type: {response.headers.get('Content-Type', 'unknown')}")
        
        if response.status_code == 200:
            # è§£æHTML
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # æŸ¥æ‰¾é¡µé¢æ ‡é¢˜
            title = soup.find('title')
            print(f"é¡µé¢æ ‡é¢˜: {title.get_text() if title else 'æœªæ‰¾åˆ°'}")
            
            # æŸ¥æ‰¾å¸¸è§çš„é¥°å“å®¹å™¨
            card_items = soup.find_all('div', class_='card-item')
            market_items = soup.find_all('div', class_='item')
            goods_items = soup.find_all('div', class_='goods-item')
            
            print(f"æ‰¾åˆ° .card-item: {len(card_items)} ä¸ª")
            print(f"æ‰¾åˆ° .item: {len(market_items)} ä¸ª")
            print(f"æ‰¾åˆ° .goods-item: {len(goods_items)} ä¸ª")
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é¢„æœŸçš„å…ƒç´ ï¼Œæ˜¾ç¤ºé¡µé¢ç»“æ„
            if len(card_items) == 0 and len(market_items) == 0:
                print("\nğŸ“‹ é¡µé¢ç»“æ„åˆ†æ:")
                
                # æŸ¥æ‰¾æ‰€æœ‰å¸¦classçš„div
                divs_with_class = soup.find_all('div', class_=True)[:10]
                for i, div in enumerate(divs_with_class, 1):
                    classes = ' '.join(div.get('class', []))
                    print(f"   {i}. <div class='{classes}'> (å†…å®¹é•¿åº¦: {len(div.get_text())})")
            
            return True
        else:
            print(f"âŒ è®¿é—®å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            return False
            
    except requests.exceptions.Timeout:
        print("âŒ è¯·æ±‚è¶…æ—¶")
        return False
    except requests.exceptions.ConnectionError:
        print("âŒ è¿æ¥é”™è¯¯ï¼Œå¯èƒ½ç½‘ç»œä¸é€šæˆ–ç½‘ç«™é™åˆ¶è®¿é—®")
        return False
    except Exception as e:
        print(f"âŒ å…¶ä»–é”™è¯¯: {e}")
        return False

def suggest_alternatives():
    """å»ºè®®æ›¿ä»£æ–¹æ¡ˆ"""
    print("\nğŸ’¡ å»ºè®®çš„è§£å†³æ–¹æ¡ˆ:")
    print("1. ä½¿ç”¨æ¼”ç¤ºæ•°æ®æ¨¡å¼ï¼ˆå·²å®ç°ï¼‰")
    print("2. ä½¿ç”¨ä»£ç†æœåŠ¡å™¨")
    print("3. ä½¿ç”¨Seleniumæµè§ˆå™¨è‡ªåŠ¨åŒ–")
    print("4. å¯»æ‰¾å…¬å¼€çš„APIæ¥å£")
    print("5. ä½¿ç”¨æœ¬åœ°ç¼“å­˜æ•°æ®")

if __name__ == "__main__":
    print("ğŸ¯ Buffçˆ¬è™«è°ƒè¯•å·¥å…·")
    print("="*40)
    
    success = test_buff_access()
    
    if not success:
        suggest_alternatives() 