#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import pickle
import json
from datetime import datetime

def check_hashname_cache():
    try:
        with open('data/hashname_cache.pkl', 'rb') as f:
            data = pickle.load(f)
        
        hashnames = data.get('hashnames', [])
        last_update = data.get('last_full_update')
        
        print(f"ğŸ” HashNameç¼“å­˜æ£€æŸ¥:")
        print(f"  ç¼“å­˜å…³é”®è¯æ•°é‡: {len(hashnames)}")
        print(f"  ä¸Šæ¬¡å…¨é‡æ›´æ–°: {last_update}")
        
        if hashnames:
            print(f"  å‰10ä¸ªå…³é”®è¯:")
            for i, keyword in enumerate(hashnames[:10], 1):
                print(f"    {i}. {keyword}")
        else:
            print("  âŒ ç¼“å­˜ä¸ºç©ºï¼è¿™ä¼šå¯¼è‡´å¢é‡æ›´æ–°æ— æ³•è¿›è¡Œ")
            
    except FileNotFoundError:
        print("âŒ ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨")
    except Exception as e:
        print(f"âŒ è¯»å–ç¼“å­˜å¤±è´¥: {e}")

def check_latest_data():
    try:
        with open('data/latest_price_diff.json', 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        metadata = data.get('metadata', {})
        items = data.get('items', [])
        
        print(f"\nğŸ“Š æœ€æ–°æ•°æ®æ£€æŸ¥:")
        print(f"  å•†å“æ•°é‡: {len(items)}")
        print(f"  ä¸Šæ¬¡å…¨é‡æ›´æ–°: {metadata.get('last_full_update')}")
        print(f"  ä¸Šæ¬¡å¢é‡æ›´æ–°: {metadata.get('last_incremental_update')}")
        print(f"  ç”Ÿæˆæ—¶é—´: {metadata.get('generated_at')}")
        
        if items:
            print(f"  å‰3ä¸ªå•†å“:")
            for i, item in enumerate(items[:3], 1):
                print(f"    {i}. {item.get('name', '')}: Â¥{item.get('price_diff', 0):.2f}")
                print(f"       æ›´æ–°æ—¶é—´: {item.get('last_updated', '')}")
                
    except FileNotFoundError:
        print("âŒ æœ€æ–°æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
    except Exception as e:
        print(f"âŒ è¯»å–æœ€æ–°æ•°æ®å¤±è´¥: {e}")

if __name__ == "__main__":
    check_hashname_cache()
    check_latest_data() 